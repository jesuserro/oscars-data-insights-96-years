{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def scrape_books(min_rating=4, max_price=20, max_pages=1):\n",
    "    base_url = \"https://books.toscrape.com/catalogue/page-{}.html\"\n",
    "    books_data = []\n",
    "\n",
    "    rating_map = {'One': 1, 'Two': 2, 'Three': 3, 'Four': 4, 'Five': 5}\n",
    "\n",
    "    page = 1\n",
    "    while page <= max_pages:\n",
    "        url = base_url.format(page)\n",
    "        response = requests.get(url)\n",
    "        response.encoding = 'utf-8'\n",
    "        if response.status_code != 200:\n",
    "            break\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        books = soup.select('ol.row > li')\n",
    "\n",
    "        if not books:\n",
    "            break\n",
    "\n",
    "        for book in books:\n",
    "            try:\n",
    "                rating_class = book.find('p', class_='star-rating')['class'][1]\n",
    "                rating = rating_map.get(rating_class, 0)\n",
    "\n",
    "                price = float(book.find('p', class_='price_color').text.replace('£', '').strip())\n",
    "\n",
    "                if rating >= min_rating and price <= max_price:\n",
    "                    title = book.h3.a['title'].strip().replace(u'\\xa0', u' ')\n",
    "                    book_url = 'https://books.toscrape.com/catalogue/' + book.h3.a['href'].replace('index.html', '')\n",
    "\n",
    "                    # Detalles adicionales del libro\n",
    "                    book_response = requests.get(book_url)\n",
    "                    book_response.encoding = 'utf-8'\n",
    "                    book_soup = BeautifulSoup(book_response.text, 'html.parser')\n",
    "\n",
    "                    upc = book_soup.find('th', string='UPC').find_next_sibling('td').text.strip()\n",
    "                    availability = book.find('p', class_='instock availability').text.strip().replace(u'\\xa0', u' ')\n",
    "                    genre = book_soup.find('ul', class_='breadcrumb').find_all('li')[2].text.strip()\n",
    "                    description_tag = book_soup.find('meta', attrs={'name': 'description'})\n",
    "                    description = description_tag['content'].strip().replace(u'\\xa0', u' ') if description_tag else 'No description'\n",
    "                    description = description.replace('\\n', ' ').replace('\\r', ' ').strip()\n",
    "\n",
    "                    books_data.append({\n",
    "                        'UPC': upc,\n",
    "                        'Title': title,\n",
    "                        'Price (£)': price,\n",
    "                        'Rating': rating,\n",
    "                        'Genre': genre,\n",
    "                        'Availability': availability,\n",
    "                        'Description': description\n",
    "                    })\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error procesando un libro: {e}\")\n",
    "                continue\n",
    "\n",
    "        # Comprobar si hay más páginas\n",
    "        next_page = soup.select_one('li.next > a')\n",
    "        if not next_page:\n",
    "            break\n",
    "        page += 1\n",
    "\n",
    "    df = pd.DataFrame(books_data)\n",
    "    return df\n",
    "\n",
    "# Ejemplo de uso\n",
    "result_df = scrape_books(min_rating=4, max_price=100, max_pages=1)\n",
    "print(result_df.head())\n",
    "\n",
    "# Guardar en CSV si se desea\n",
    "result_df.to_csv('data/budgets.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
